{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8ef75209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import get_scheduler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17bcfbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = \"data/implicit-hate-corpus/\"\n",
    "PATH_INPUT_POSTS = \"implicit_hate_v1_SAP_posts.tsv\"\n",
    "PATH_HATE_LABEL = \"implicit_hate_v1_stg1.tsv\"\n",
    "PATH_CATEGORY_LABEL = \"implicit_hate_v1_stg2.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d6829d",
   "metadata": {},
   "source": [
    "# Implicit hate speech detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5a84f2",
   "metadata": {},
   "source": [
    "Get help from this [kaggle page](https://www.kaggle.com/code/yousefadham/working-hatebert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e502c0",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3929b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = pd.read_csv(PATH_DATA + PATH_INPUT_POSTS, sep = '\\t')\n",
    "hate_labels = pd.read_csv(PATH_DATA + PATH_HATE_LABEL, sep = '\\t')\n",
    "category_labels = pd.read_csv(PATH_DATA + PATH_CATEGORY_LABEL, sep = '\\t')\n",
    "\n",
    "num_labels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89670793",
   "metadata": {},
   "source": [
    "# Load the Hate Bert model\n",
    "\n",
    "We decide to use the Hate Bert model, a Bert model specially trained to detect hate. This model can be use from hugging face [plateforme](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c72488e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/hateBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"GroNLP/hateBERT\",\n",
    "    num_labels=num_labels,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc5b315",
   "metadata": {},
   "source": [
    "# Load the tokenizer\n",
    "\n",
    "From hugging face plateforme, we can also load the tokenizer specially made for Hate Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2699a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/hateBERT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35591758",
   "metadata": {},
   "source": [
    "## DataLoader initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6fea2929",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenize the text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca3caaf",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb5be09",
   "metadata": {},
   "source": [
    "First let's visualise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "797a9789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAP_10011</td>\n",
       "      <td>Guys I have a question: when a gay couple gets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAP_10036</td>\n",
       "      <td>Heard this from a 12 year old: 'Whats the diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SAP_10045</td>\n",
       "      <td>Friend: how dark is your humor? Me: If you whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAP_10051</td>\n",
       "      <td>What do you say to a black guy in a three piec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SAP_10085</td>\n",
       "      <td>how do you call a black man you call his cell ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>SAP_9953</td>\n",
       "      <td>How do you get a black man out of a tree? Cut ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>SAP_9960</td>\n",
       "      <td>Helen Keller walked into a bar and then a chai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>SAP_9962</td>\n",
       "      <td>Why do sumo wrestlers shave their legs? So tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>SAP_9966</td>\n",
       "      <td>What's the difference between a black slave an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>SAP_9989</td>\n",
       "      <td>Why did Beyonce say \"to the left,to the left\"?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                               post\n",
       "0    SAP_10011  Guys I have a question: when a gay couple gets...\n",
       "1    SAP_10036  Heard this from a 12 year old: 'Whats the diff...\n",
       "2    SAP_10045  Friend: how dark is your humor? Me: If you whi...\n",
       "3    SAP_10051  What do you say to a black guy in a three piec...\n",
       "4    SAP_10085  how do you call a black man you call his cell ...\n",
       "..         ...                                                ...\n",
       "543   SAP_9953  How do you get a black man out of a tree? Cut ...\n",
       "544   SAP_9960  Helen Keller walked into a bar and then a chai...\n",
       "545   SAP_9962  Why do sumo wrestlers shave their legs? So tha...\n",
       "546   SAP_9966  What's the difference between a black slave an...\n",
       "547   SAP_9989  Why did Beyonce say \"to the left,to the left\"?...\n",
       "\n",
       "[548 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f674d315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>399886440588247041</td>\n",
       "      <td>implicit_hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>929901925100937216</td>\n",
       "      <td>not_hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>728678509497954304</td>\n",
       "      <td>not_hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>625688620444180481</td>\n",
       "      <td>not_hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>441089979322597376</td>\n",
       "      <td>not_hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21475</th>\n",
       "      <td>SAP_17154</td>\n",
       "      <td>implicit_hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21476</th>\n",
       "      <td>SAP_17179</td>\n",
       "      <td>implicit_hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21477</th>\n",
       "      <td>SAP_17314</td>\n",
       "      <td>implicit_hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21478</th>\n",
       "      <td>SAP_17343</td>\n",
       "      <td>implicit_hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21479</th>\n",
       "      <td>SAP_17406</td>\n",
       "      <td>implicit_hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21480 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID          class\n",
       "0      399886440588247041  implicit_hate\n",
       "1      929901925100937216       not_hate\n",
       "2      728678509497954304       not_hate\n",
       "3      625688620444180481       not_hate\n",
       "4      441089979322597376       not_hate\n",
       "...                   ...            ...\n",
       "21475           SAP_17154  implicit_hate\n",
       "21476           SAP_17179  implicit_hate\n",
       "21477           SAP_17314  implicit_hate\n",
       "21478           SAP_17343  implicit_hate\n",
       "21479           SAP_17406  implicit_hate\n",
       "\n",
       "[21480 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175f1b40",
   "metadata": {},
   "source": [
    "We can notice that they are more classification than the number of input posts. -> Why is this like this ?  <br>\n",
    "To overcome this issue, we remove every label that don't correpsond to a post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "302cabbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_labels = hate_labels[\"ID\"][hate_labels[\"ID\"].isin(input[\"ID\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set some general constant that will be used in the entire code\n",
    "RANDOM_SEED = 42\n",
    "MAX_LENGTH = 128 # -> What is this ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c99fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the data into train and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    input, hate_labels, test_size=0.2, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "#Create the dataset\n",
    "train_dataset = HateSpeechDataset(\n",
    "    texts=train_texts,\n",
    "    labels=train_labels,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=MAX_LENGTH\n",
    ")\n",
    "\n",
    "#Create the test dataset\n",
    "test_dataset = HateSpeechDataset(\n",
    "    texts=test_texts,\n",
    "    labels=test_labels,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=MAX_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90928ba3",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "We use the default training configuration from the kaggle page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a0de70d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = torch.tensor([len(train_dataset) / (7 * 15294),  # toxic\n",
    "                              len(train_dataset) / (7 * 1595),   # severe_toxic\n",
    "                              len(train_dataset) / (7 * 8449),   # obscene\n",
    "                              len(train_dataset) / (7 * 478),    # threat\n",
    "                              len(train_dataset) / (7 * 7877),   # insult\n",
    "                              len(train_dataset) / (7 * 1405),   # identity_hate\n",
    "                              len(train_dataset) / (7 * 143346)  # normal\n",
    "                             ]).to(device)\n",
    "\n",
    "# Use weighted BCEWithLogitsLoss\n",
    "criterion = BCEWithLogitsLoss(weight=class_weights)\n",
    "\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ac591",
   "metadata": {},
   "source": [
    "Do we want to use a scheduler ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9e46a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "num_training_steps = num_epochs * len(train_dataset)\n",
    "# feel free to experiment with different num_warmup_steps\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=1, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "957a8d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last = True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "664d49d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/876 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "333",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ovola\\anaconda3\\envs\\DL\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 333",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# iterate over epochs\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# iterate over batches in training set\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;250;43m        \u001b[39;49m\u001b[33;43;03m'''\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[33;43;03m        **kwargs is a common idiom to allow an arbitrary number of arguments to functions\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[33;43;03m        The **kwargs will give you all keyword arguments as a dictionary\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[33;43;03m        https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[33;43;03m        '''\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ovola\\anaconda3\\envs\\DL\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ovola\\anaconda3\\envs\\DL\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    756\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    759\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ovola\\anaconda3\\envs\\DL\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mHateSpeechDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     text = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m     13\u001b[39m     label = \u001b[38;5;28mself\u001b[39m.labels[idx]\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Tokenize the text\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ovola\\anaconda3\\envs\\DL\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ovola\\anaconda3\\envs\\DL\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 333"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "# put the model in train mode\n",
    "model.train()\n",
    "\n",
    "# iterate over epochs\n",
    "for epoch in range(num_epochs):\n",
    "    # iterate over batches in training set\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        '''\n",
    "        **kwargs is a common idiom to allow an arbitrary number of arguments to functions\n",
    "        The **kwargs will give you all keyword arguments as a dictionary\n",
    "        https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters\n",
    "        '''\n",
    "        \n",
    "\n",
    "        outputs = model(**batch)\n",
    "        '''\n",
    "        Note that Transformers models all have a default task-relevant loss function,\n",
    "        so you donâ€™t need to specify one unless you want to\n",
    "\n",
    "        Get the loss form the outputs\n",
    "        in this example, the outputs are instances of subclasses of ModelOutput\n",
    "        https://huggingface.co/transformers/v4.3.0/main_classes/output.html\n",
    "        Those are data structures containing all the information returned by\n",
    "        the model, but that can also be used as tuples or dictionaries.\n",
    "\n",
    "        The outputs object has a loss and logits attribute\n",
    "        You can access each attribute as you would usually do,\n",
    "        and if that attribute has not been returned by the model, you will get None.\n",
    "        for instance, outputs.loss is the loss computed by the model\n",
    "        '''\n",
    "\n",
    "        ### BEGIN SOLUTION\n",
    "        loss = outputs.loss\n",
    "        ### END SOLUTION\n",
    "\n",
    "        # do the backward pass\n",
    "        ### BEGIN SOLUTION\n",
    "        loss.backward()\n",
    "        ### END SOLUTION\n",
    "\n",
    "        # perform one step of the optimizer\n",
    "        ### BEGIN SOLUTION\n",
    "        optimizer.step()\n",
    "        ### END SOLUTION\n",
    "\n",
    "        # peform one step of the lr_scheduler, similar with the optimizer\n",
    "        ### BEGIN SOLUTION\n",
    "        lr_scheduler.step()\n",
    "        ### END SOLUTION\n",
    "\n",
    "        # zero the gradients, call zero_grad() on the optimizer\n",
    "        ### BEGIN SOLUTION\n",
    "        optimizer.zero_grad()\n",
    "        ### END SOLUTION\n",
    "\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0688f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# define the metric you want to use to evaluate your model\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "progress_bar = tqdm(range(len(eval_dataloader)))\n",
    "\n",
    "# put the model in eval mode\n",
    "model_bert_l4.eval()\n",
    "# iterate over batches of evaluation dataset\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        '''\n",
    "        pass the batches to the model and get the outputs\n",
    "        (hint: look at the training loop)\n",
    "        outputs = ...\n",
    "        '''\n",
    "        ### BEGIN SOLUTION\n",
    "        outputs = model_bert_l4(**batch)\n",
    "        ### END SOLUTION\n",
    "\n",
    "    \n",
    "    '''\n",
    "    get the logits from the outputs,\n",
    "    similar as you did for the loss in the training loop\n",
    "    logits = ...\n",
    "    '''\n",
    "    ### BEGIN SOLUTION\n",
    "    logits = outputs.logits\n",
    "    ### END SOLUTION\n",
    "\n",
    "    # use argmax to get the predicted class\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    '''\n",
    "    metric.add_batch() adds a batch of predictions and references\n",
    "    Metric.add_batch() by passing it your model predictions, and the references\n",
    "    the model predictions should be evaluated against\n",
    "    '''\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    progress_bar.update(1)\n",
    "# calculate a metric by  calling metric.compute()\n",
    "metric.compute()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
