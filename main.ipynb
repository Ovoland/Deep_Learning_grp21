{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "686ee1da",
   "metadata": {},
   "source": [
    "# DÃ©tection de Discours Haineux Implicite avec HateBERT\n",
    "\n",
    "## 1. Imports et Configuration Initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef75209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import get_scheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from IPython.display import clear_output\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574bda22",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d23529",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'GroNLP/hateBERT'\n",
    "DATA_PATH = 'data/implicit-hate-corpus/implicit_hate_v1_stg1_posts.tsv' \n",
    "MAX_LENGTH = 512 #max size of the tokenizer https://huggingface.co/GroNLP/hateBERT/commit/f56d507e4b6a64413aff29e541e1b2178ee79d67\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "TEST_SPLIT_SIZE = 0.2 # validation split\n",
    "RANDOM_SEED = 42\n",
    "NUM_LABELS = 3 # 0: not hate, 1: implicit hate, 2: explicit hate /// \n",
    "\n",
    "# Set device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e502c0",
   "metadata": {},
   "source": [
    "## 3. Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3929b979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    post          class\n",
      "0        \" : jewish harvard professor noel ignatiev w...  implicit_hate\n",
      "1       b.higher education is a part of european cult...       not_hate\n",
      "2       has a problem with  \" the whites \" \" and \" \" ...       not_hate\n",
      "3       is yasir qadhi a hate preacher for calling ch...       not_hate\n",
      "4       rt  \" : how three million germans mass murder...       not_hate\n",
      "...                                                  ...            ...\n",
      "21475  Seeing prostitutes is morally wrong, but being...  implicit_hate\n",
      "21476  I wonder how many females I raped today I spen...  implicit_hate\n",
      "21477  Having a criminal record is more attractive to...  implicit_hate\n",
      "21478  Another advantage of being a female: getting b...  implicit_hate\n",
      "21479  If men are so privileged and women have it so ...  implicit_hate\n",
      "\n",
      "[21480 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#PATH_DATA = \"data/implicit-hate-corpus/\"\n",
    "#PATH_INPUT_POSTS = \"implicit_hate_v1_SAP_posts.tsv\"\n",
    "#PATH_HATE_LABEL = \"implicit_hate_v1_stg1.tsv\"\n",
    "#PATH_CATEGORY_LABEL = \"implicit_hate_v1_stg2.tsv\"\n",
    "\n",
    "#input = pd.read_csv(PATH_DATA + PATH_INPUT_POSTS, sep = '\\t')\n",
    "#hate_labels = pd.read_csv(PATH_DATA + PATH_HATE_LABEL, sep = '\\t')\n",
    "#category_labels = pd.read_csv(PATH_DATA + PATH_CATEGORY_LABEL, sep = '\\t')\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(DATA_PATH, sep = '\\t')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2721dd",
   "metadata": {},
   "source": [
    "## 4. Data Set  Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd3c387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_counts = data['class'].value_counts()\n",
    "\n",
    "# Plot\n",
    "ax = class_counts.plot(kind='bar', title='Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "for i, count in enumerate(class_counts):\n",
    "    plt.text(i, count + max(class_counts)*0.01, str(count), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results/figures/class_distribution.png\")\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ff0a7",
   "metadata": {},
   "source": [
    "## 5. Data preparation (labels and text extraction and remaping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9470f2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels before mapping: \n",
      " ['implicit_hate' 'not_hate' 'not_hate' 'not_hate' 'not_hate' 'not_hate'\n",
      " 'implicit_hate' 'not_hate' 'explicit_hate' 'explicit_hate' 'not_hate']\n",
      "Labels after mapping:   [1 0 0 0 0 0 1 0 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "#Can select only a subset of the data\n",
    "data = data.head(20)\n",
    "\n",
    "# Label mappings\n",
    "id2label = {0: \"not_hate\", 1: \"implicit_hate\", 2: \"explicit_hate\"}\n",
    "label2id = {\"not_hate\": 0, \"implicit_hate\": 1, \"explicit_hate\": 2}\n",
    "\n",
    "\n",
    "# Load data text\n",
    "texts = data['post'].values\n",
    "\n",
    "# Print raw numeric labels\n",
    "print(\"Labels before mapping: \\n\", data['class'].values[:11])\n",
    "\n",
    "# Map labels to numeric values\n",
    "data['class'] = data['class'].map(label2id)\n",
    "labels = data['class'].values\n",
    "# Print string labels\n",
    "print(\"Labels after mapping:  \", labels[:11])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89670793",
   "metadata": {},
   "source": [
    "# 6. Load Hate Bert model\n",
    "\n",
    "We decide to use the Hate Bert model, a Bert model specially trained to detect hate. This model can be use from hugging face [plateforme](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c72488e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/hateBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109484547\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=NUM_LABELS,\n",
    "    id2label=id2label, \n",
    "    label2id=label2id,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "print(model.num_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc5b315",
   "metadata": {},
   "source": [
    "# 7. Load Tokenizer\n",
    "\n",
    "From hugging face plateforme, we can also load the tokenizer specially made for Hate Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae2699a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35591758",
   "metadata": {},
   "source": [
    "# 8. Dataset Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fea2929",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenize the text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return  {\n",
    "                'input_ids': encoding['input_ids'].flatten(),\n",
    "                'attention_mask': encoding['attention_mask'].flatten(),\n",
    "                'labels': torch.tensor(label, dtype=torch.long)\n",
    "            }\n",
    "    \n",
    "        \n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92f5141",
   "metadata": {},
   "source": [
    "# 9. Dataset and DataLoader Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0ad20ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting data (80% train and 20% test)\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# TRAIN dataset\n",
    "train_dataset = HateSpeechDataset(\n",
    "    texts=train_texts,\n",
    "    labels=train_labels,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=MAX_LENGTH\n",
    ")\n",
    "\n",
    "# TESTING dataset\n",
    "test_dataset = HateSpeechDataset(\n",
    "    texts=test_texts,\n",
    "    labels=test_labels,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=MAX_LENGTH\n",
    ")\n",
    "\n",
    "\n",
    "# DATALOADER for training set\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# DATALOADER for testing set\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90928ba3",
   "metadata": {},
   "source": [
    "# 10. Training Configuration\n",
    "\n",
    "We use the default training configuration from the kaggle page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0de70d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Class distribution from your dataset\n",
    "class_counts = [13291, 7100, 1089]\n",
    "total = sum(class_counts)\n",
    "\n",
    "# Inverse frequency (optional: normalize)\n",
    "class_weights = [total / c for c in class_counts]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# Use weighted BCEWithLogitsLoss\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ac591",
   "metadata": {},
   "source": [
    "# 11. Scheduler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e46a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_steps = EPOCHS * len(train_dataloader)\n",
    "# feel free to experiment with different num_warmup_steps\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=1, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa867e6",
   "metadata": {},
   "source": [
    "# 12. Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0b60603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, criterion, metrics, train_dataloader, device, epoch, progress_bar):\n",
    "    # Put the model in train mode\n",
    "    model.train()\n",
    "\n",
    "    # Initialize epoch loss\n",
    "    epoch_loss = 0\n",
    "    epoch_metrics = dict(zip(metrics.keys(), torch.zeros(len(metrics))))\n",
    "\n",
    "    # Use tqdm for iterating over the dataloader to see epoch progress\n",
    "    train_iterator = tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{EPOCHS} Training', leave=False)\n",
    "\n",
    "    # Iterate over batches in training set\n",
    "    for batch in train_iterator:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        target = batch[\"labels\"]  # Get the target labels\n",
    "\n",
    "        # Forward pass, get the outputs from the model\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=target)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(logits, target)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform one step of the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        # Learning rate scheduler step\n",
    "        if 'lr_scheduler' in globals():\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        # Use argmax to get the predicted class\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Update each metric with the current batch\n",
    "        with torch.no_grad():\n",
    "            for k in epoch_metrics.keys():\n",
    "                epoch_metrics[k] += metrics[k](preds.cpu(), target.cpu())\n",
    "\n",
    "        # Update loss\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    # for the epoch loss, we compute the average of the metrics over the mini-batches\n",
    "    for k in epoch_metrics.keys():\n",
    "          epoch_metrics[k] /= len(train_dataloader)\n",
    "    \n",
    "    # Average the loss over all batches\n",
    "    epoch_loss /= len(train_dataloader)\n",
    "\n",
    "    # Clear the output and print epoch statistics\n",
    "    clear_output()  # Clean the prints from previous epochs\n",
    "    print('Train Loss: {:.4f}, '.format(epoch_loss),\n",
    "          ', '.join(['{}: {:.4f}'.format(k, v) for k, v in epoch_metrics.items()]))\n",
    "\n",
    "    return epoch_loss, epoch_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e81249",
   "metadata": {},
   "source": [
    "# 13. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0688f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, criterion, metrics, test_dataloader, device, epoch, progress_bar):\n",
    "    # Put the model in eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize lists to store predictions and true labels\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_metrics = dict(zip(metrics.keys(), torch.zeros(len(metrics))))\n",
    "\n",
    "    # Use tqdm for the evaluation dataloader\n",
    "    eval_iterator = tqdm(test_dataloader, desc='Evaluating Test Set')\n",
    "\n",
    "    # Iterate over batches of evaluation dataset\n",
    "    for batch in eval_iterator:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        target = batch[\"labels\"]  # Get the target labels\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, get the outputs from the model\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=target)\n",
    "\n",
    "            # Get the logits from the outputs\n",
    "            logits = outputs.logits\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(logits, target)\n",
    "    \n",
    "        # Use argmax to get the predicted class\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        # Append predictions and true labels to the lists\n",
    "        all_predictions.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(target.cpu().numpy())\n",
    "\n",
    "        # Update each metric with the current batch\n",
    "        with torch.no_grad():\n",
    "            for k in epoch_metrics.keys():\n",
    "                epoch_metrics[k] += metrics[k](preds.cpu(), target.cpu())\n",
    "                \n",
    "        # Update loss\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "        progress_bar.update(1)\n",
    "\n",
    "    for k in epoch_metrics.keys():\n",
    "          epoch_metrics[k] /= len(test_dataloader)\n",
    "        \n",
    "    # Average the loss over all batches\n",
    "    epoch_loss /= len(test_dataloader)\n",
    "\n",
    "    # Print evaluation results\n",
    "    print('Eval Loss: {:.4f}, '.format(epoch_loss),\n",
    "          ', '.join(['{}: {:.4f}'.format(k, v) for k, v in epoch_metrics.items()]))\n",
    "\n",
    "    return epoch_loss, epoch_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21db3df",
   "metadata": {},
   "source": [
    "# 14. Plotting the training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c191d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(train_loss, test_loss, metrics_names, train_metrics_logs, test_metrics_logs, savePicture = True):\n",
    "    fig, ax = plt.subplots(1, len(metrics_names) + 1, figsize=((len(metrics_names) + 1) * 5, 5))\n",
    "\n",
    "    ax[0].plot(train_loss, c='blue', label='train')\n",
    "    ax[0].plot(test_loss, c='orange', label='test')\n",
    "    ax[0].set_title('Loss')\n",
    "    ax[0].set_xlabel('epoch')\n",
    "    ax[0].legend()\n",
    "\n",
    "    for i in range(len(metrics_names)):\n",
    "        ax[i + 1].plot(train_metrics_logs[i], c='blue', label='train')\n",
    "        ax[i + 1].plot(test_metrics_logs[i], c='orange', label='test')\n",
    "        ax[i + 1].set_title(metrics_names[i])\n",
    "        ax[i + 1].set_xlabel('epoch')\n",
    "        ax[i + 1].legend()\n",
    "\n",
    "    fig.suptitle(\"Training result of HateBert\")\n",
    "    fig.savefig('results/figures/training_plot.png')\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def update_metrics_log(metrics_names, metrics_log, new_metrics_dict):\n",
    "    '''\n",
    "    - metrics_names: the keys/names of the logged metrics\n",
    "    - metrics_log: existing metrics log that will be updated\n",
    "    - new_metrics_dict: epoch_metrics output from train_epoch and evaluate functions\n",
    "    '''\n",
    "    for i in range(len(metrics_names)):\n",
    "        curr_metric_name = metrics_names[i]\n",
    "        metrics_log[i].append(new_metrics_dict[curr_metric_name])\n",
    "    return metrics_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28145930",
   "metadata": {},
   "source": [
    "# 15. Iterative training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21ae200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(model, optimizer, criterion, metrics, train_loader, test_loader, n_epochs, device):\n",
    "    train_loss_log,  test_loss_log = [], []\n",
    "    metrics_names = list(metrics.keys())\n",
    "    train_metrics_log = [[] for i in range(len(metrics))]\n",
    "    test_metrics_log = [[] for i in range(len(metrics))]\n",
    "\n",
    "    num_training_steps = n_epochs * len(train_dataloader)\n",
    "\n",
    "    progress_bar = tqdm(range(num_training_steps), desc=\"Training Progress\")\n",
    "\n",
    "    print(f\"Starting training for {EPOCHS} epochs...\") # Use EPOCHS from config\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {0} of {1}\".format(epoch, n_epochs))\n",
    "        train_loss, train_metrics = train_epoch(model, optimizer, criterion, metrics, train_loader, device,epoch, progress_bar)\n",
    "\n",
    "        test_loss, test_metrics = testing(model, criterion, metrics, test_loader, device,epoch, progress_bar)\n",
    "\n",
    "        train_loss_log.append(train_loss)\n",
    "        train_metrics_log = update_metrics_log(metrics_names, train_metrics_log, train_metrics)\n",
    "\n",
    "        test_loss_log.append(test_loss)\n",
    "        test_metrics_log = update_metrics_log(metrics_names, test_metrics_log, test_metrics)\n",
    "\n",
    "        plot_training(train_loss_log, test_loss_log, metrics_names, train_metrics_log, test_metrics_log)\n",
    "\n",
    "    progress_bar.close()\n",
    "    print(\"Training completed.\")\n",
    "    return train_metrics_log, test_metrics_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a84043-488f-473f-ae98-facf7ef38de0",
   "metadata": {},
   "source": [
    "# 16 Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f3fc1b7-3576-43c3-ace5-1f1829e7f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(preds, target):\n",
    "    return f1_score(target, preds, average='macro')\n",
    "\n",
    "def acc(preds, target):\n",
    "    return accuracy_score(target, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba475f0",
   "metadata": {},
   "source": [
    "# 17. Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8930925d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfcdc3058a34be38d5a50e21e5ce4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 3 epochs...\n",
      "Epoch 0 of 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ce5ce6f5504e3e8c2f025b4a70e846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 Training:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = {'ACC': acc, 'F1-weighted': f1}\n",
    "\n",
    "model.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "train_metrics_log, test_metrics_log = training_model(model, optimizer, criterion, metrics, train_dataloader, test_dataloader, n_epochs=EPOCHS, device=device)\n",
    "\n",
    "# save model weights\n",
    "results_models_weights_dir = 'results/models_weights/'\n",
    "if not os.path.exists(results_models_weights_dir):\n",
    "    os.mkdir(results_models_weights_dir)\n",
    "torch.save(model.state_dict(), results_models_weights_dir + 'base_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d4d3f5-a21c-49a5-9265-25c76555a118",
   "metadata": {},
   "source": [
    "# Classification example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "902ea9e5-5a5e-4757-9b60-1c455b014d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example classification: not_hate\n"
     ]
    }
   ],
   "source": [
    "n = -1\n",
    "example_text = texts[n]\n",
    "example_label = labels[n]\n",
    "print(f\"Example classification: {id2label[example_label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ed8685e-3fdf-4352-b57d-c73eb7421d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(example_text, example_label): \n",
    "    #Using the HateBertDataLoader is a bit overkilled, we can just tokenize the input\n",
    "    encoded_input = tokenizer(\n",
    "        example_text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Forward pass, get the outputs from the model\n",
    "        outputs = model(**encoded_input)\n",
    "        \n",
    "        # Get the logits from the outputs\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # Use argmax to get the predicted class\n",
    "    preds = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    print(f\"Example sentence: {example_text}\")\n",
    "    print(f\" ---- Model classification: {id2label[int(preds)]}\") \n",
    "    print(f\" ---- Real classification: {id2label[example_label]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d82d1d6-44f7-4874-803a-bc4f43b61634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence:   \" : jewish harvard professor noel ignatiev wants to abolish the white race via #wr \" \" \"\n",
      " ---- Model classification: explicit_hate\n",
      " ---- Real classification: implicit_hate \n",
      "\n",
      "Example sentence: : cnn wants black people to think the president is racist . look around you  your\n",
      " ---- Model classification: explicit_hate\n",
      " ---- Real classification: not_hate \n",
      "\n",
      "Example sentence: : : hate posters ? you want hate buddy ? read the koran . goo ...\n",
      " ---- Model classification: implicit_hate\n",
      " ---- Real classification: implicit_hate \n",
      "\n",
      "Example sentence: 3 ) a white supremacist drove his car into a crowd of people\n",
      " ---- Model classification: explicit_hate\n",
      " ---- Real classification: not_hate \n",
      "\n",
      "Example sentence: . pretty sure trump doesn't want incompetents on his team ...\n",
      " ---- Model classification: explicit_hate\n",
      " ---- Real classification: not_hate \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(0,-5,-1):\n",
    "    example_text = texts[n]\n",
    "    example_label = labels[n]\n",
    "    classification(example_text, example_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
